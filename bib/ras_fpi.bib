@INPROCEEDINGS{peg_personal_icra_2010,
	author		={W. Meeussen and et. al},
	booktitle 	={International Conference on Robotics and Automation (ICRA)},
	title 		={Autonomous door opening and plugging in with a personal robot},
	year 		={2010},
	pages 		={729-736},
	doi 		={10.1109/ROBOT.2010.5509556},
	month	 	={May}
}

@inbook{fast_peg_pbd_icmc_2014,
	title  		= "Fast programming of peg-in-hole actions by human demonstration",
	author  	= "Yang Yang and et al.",
	year 		= "2014",
	pages 		= "990--995",
	booktitle 	= "International Conference on Mechatronics and Control (ICMC)",
	doi  		= "10.1109/ICMC.2014.7231702"
}


@inproceedings{learn_admittance_icra_1994,
  author    = {Vijaykumar Gullapalli and Andrew G. Barto and Roderic A. Grupen},
  title     = {Learning Admittance Mappings for Force-Guided Assembly},
  booktitle = {International Conference on Robotics and Automation (ICRA)},
  pages     = {2633--2638},
  year      = {1994},
  doi       = {10.1109/ROBOT.1994.351117}
}


@INPROCEEDINGS{online_gpr_icra_2014,
	author 		={H. Cheng and H. Chen},
	booktitle	={International Conference on Robotics and Automation (ICRA)},
	title		={Online parameter optimization in robotic force controlled assembly processes},
	year 		={2014},
	pages 		={3465-3470},
	month 		={May},
	doi		={10.1109/ICRA.2014.6907358}
}

@INPROCEEDINGS{feed_icra_2010,
	author		={B. Mayton and L. LeGrand and J. R. Smith},
	booktitle 	={International Conference on Robotics and Automation (ICRA)},
	title 		={Robot, feed thyself: Plugging in to unmodified electrical outlets by sensing emitted AC electric fields},
	year 		={2010},
	pages 		={715-722},
	Month		={May},
	doi 		={10.1109/ROBOT.2010.5509643}
}

@INPROCEEDINGS{pomdp_peg_icra_2014,
	author 	  ={H. Cheng and H. Chen and L. Hao and W. Li},
	booktitle ={International Conference on Robotics and Automation (ICRA)},
	title 	  ={Robot learning based on Partial Observable Markov Decision Process in unstructured environment},
	year 	  ={2014},
	pages 	  ={4399-4404},
	month 	  ={May},
	doi 	  ={10.1109/ICRA.2014.6907500}
}


@INPROCEEDINGS{search_strategies_icra_2001,
	author 		={S. R. Chhatpar and M. S. Branicky},
	booktitle	={International Conference on Intelligent Robots and Systems (IROS)},
	title 		={Search strategies for peg-in-hole assemblies with position uncertainty},
	year 		={2001},
	volume 		={3},
	pages 		={1465-1470},
	doi 		={10.1109/IROS.2001.977187},
}

@article{sol_pdg_pbd_2014,
	author  	= "Fares Abu-Dakka and Bojan Nemec and Aljaz Kramberger and Anders Glent Buch and Norbert Kr{\"u}ger and Ales Ude",
	title 		= "Solving peg-in-hole tasks by human demonstration and exception strategies",
	journal 	= "Industrial Robot",
	number 		= "6",
	pages 		= "575--584",
	volume 		= "41",
	year 		= "2014",
	doi 		= "http://dx.doi.org/10.1108/IR-07-2014-0363"
}

@INPROCEEDINGS{learn_force_c_icirs_2011,
	author 		={M. Kalakrishnan and L. Righetti and P. Pastor and S. Schaal},
	booktitle	={International Conference on Intelligent Robots and Systems (IROS)},
	title 		={Learning force control policies for compliant manipulation},
	year 		={2011},
	pages		={4639-4644},
	month		={Sept},
	doi 		={10.1109/IROS.2011.6095096}
}

@INPROCEEDINGS{Schaal04learningmovement,
    	author 		= {Stefan Schaal and Jan Peters and Jun Nakanishi and Auke Ijspeert},
    	title 		= {Learning movement primitives},
    	booktitle 	= {International Symposium on Robotics Research (ISRR)},
    	year 		= {2004}
}

@INPROCEEDINGS{trans_workpiece_icra_2013,
	author		={B. Nemec and F. J. Abu-Dakka and B. Ridge and A. Ude and J. A. Jorgensen and T. R. Savarimuthu and J. Jouffroy and H. G. Petersen and N. Kr\"uger},
	booktitle 	={International Conference on Advanced Robotics},
	title 		={Transfer of assembly operations to new workpiece poses by adaptation to the desired force profile},
	year 		={2013},
	pages 		={1-7},
	month 		={Nov},
	doi 		={10.1109/ICAR.2013.6766568},
}	


@INPROCEEDINGS{compliant_manip_icra_2008,
	author		={Seung-kook Yun},
	booktitle	={Robotics and Automation, 2008. ICRA 2008. IEEE International Conference on},
	title 		={Compliant manipulation for peg-in-hole: Is passive compliance a key to learn contact motion?},
	year 		={2008},
	pages 		={1647-1652},
	month		={May},
	doi 		={10.1109/ROBOT.2008.4543437}
}

@article{rl_gradient_survey_2013,
	author 		= {Marc Peter Deisenroth and Gerhard Neumann and Jan Peters},
	title 		= {A Survey on Policy Search for Robotics},
	year 		= {2013},
	volume 		= {2},
	journal 	= {Foundations and Trends in Robotics},
	number 		= {1-2},
	pages 		= {1-142},
	doi 		= {10.1561/2300000021}
}


@Article{Kober2011,
	author 		="Kober, Jens and Peters, Jan",
	title 		="Policy search for motor primitives in robotics",
	journal		="Machine Learning",
	year 		="2011",
	volume 		="84",
	number 		="1",
	pages 		="171--203",
	doi 		="10.1007/s10994-010-5223-6"
}

@article{Kormushev_MDPI_2013,
  	author 		= {Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G.},
  	title 		= {Reinforcement Learning in Robotics: Applications and Real-World Challenges},
  	journal 	= {Robotics},
  	volume 		= {2},
  	year 		= {2013},
  	number 		= {3},
  	pages 		= {122--148},
  	doi 		= {10.3390/robotics2030122}
}

@INPROCEEDINGS{dmp_grasp_iros_2011,
	author		={F. Stulp and E. Theodorou and M. Kalakrishnan and P. Pastor and L. Righetti and S. Schaal},
	booktitle	={International Conference on Intelligent Robots and Systems (IROS)},
	title 		={Learning motion primitive goals for robust manipulation},
	year 		={2011},
	pages 		={325-331},
	month 		={Sept},
	doi 		={10.1109/IROS.2011.6094877}
}

@Article{Chambrier2014,
	author 		="Chambrier, Guillaume de and Billard, Aude",
	title 		="Learning search policies from humans in a partially observable context",
	journal 	="Journal of Robotics and Biomimetics",
	year 		="2014",
	volume 		="1",
	number 		="1",
	pages 		="1--16",
	doi 		="10.1186/s40638-014-0008-1"
}

@article{peter_nac_2008,
  	title  		= {Natural Actor-Critic},
  	author 		= {Peters, J. and Schaal, S.},
  	journal  	= {Neurocomputing},
  	volume 		= {71},
  	number  	= {7-9},
  	pages  		= {1180-1190},
  	year  		= {2008}
}

@ARTICLE{gesture_calinon_2010,
	author={S. Calinon and F. D'halluin and E. L. Sauser and D. G. Caldwell and A. G. Billard},
	journal={IEEE Robotics Automation Magazine},
	title={Learning and Reproduction of Gestures by Imitation},
	year={2010},
	volume={17},
	number={2},
	pages={44-54},
	month={June}
}

@phdthesis{gmr_2004,
  author       = {Sung, H.G}, 
  title        = {Gaussian Mixture Regression and Classification},
  school       = {Rice University},
  year         = 2004,
}


@article{DeisenrothNP2013,
  title = {A Survey on Policy Search for Robotics, Foundations and Trends in Robotics},
  author = {Deisenroth, MP. and Neumann, G. and Peters, J.},
  journal = {Foundations and Trends in Robotics},
  volume = {2},
  number = {1-2},
  pages = {1-142},
  year = {2013}
}

@Book{Szepesvari:2010,
  author =       "Szepesv{\'a}ri, Csaba",
  title =        "Algorithms for Reinforcement Learning",
  publisher =    "Morgan {\&} Claypool",
  year =         "2010"
}

@INPROCEEDINGS{Boyan95generalizationin,
    author = {Justin A. Boyan and Andrew W. Moore},
    title = {Generalization in Reinforcement Learning: Safely Approximating the Value Function},
    booktitle = {Advances in Neural Information Processing Systems (NIPS)},
    volume = {7},
    year = {1995},
    pages = {369--376}
}

@ARTICLE{Atkeson97locallyweighted,
    author = {Christopher G. Atkeson and Andrew W. Moore and Stefan Schaal},
    title = {Locally weighted learning},
    journal = {Artificial Intelligence review},
    year = {1997},
    pages = {11--73}
}

@incollection{NIPS2008_3501,
	title  		= {Fitted Q-iteration by Advantage Weighted Regression},
	author  	= {Neumann, Gerhard and Jan R. Peters},
	booktitle  	= {Advances in Neural Information Processing Systems (NIPS) },
	volume  	= {21},
	publisher 	= {Curran Associates, Inc.},
	editor  	= {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
	pages  		= {1177--1184},
	year  		= {2009}
}

@book{sutton1998reinforcement,
  author = {Sutton, R.S. and Barto, A.G.},
  publisher = {Cambridge Univ Press},
  title = {Reinforcement learning: An introduction},
  volume = 116,
  year = 1998
}

@Book{Bishop_2006,
  author =       "Bishop, Christopher M.",
  title =        "Pattern Recognition and Machine Learning",
  publisher =    "Springer",
  year =         "2006"
}


@article{EBurdet1999,
	author 	= {Burdet, E and Nuttin, M},
	journal = {Journal of Intelligent and Robotic Systems},
	number 	= {1},
	pages 	= {43--68},
	title 	= {{Learning Complex Tasks Using a Stepwise Approach}},
	volume 	= {24},
	doi 	= {10.1023/A:1008058131402}
}

@INPROCEEDINGS{Gullapalli_1994,
	author 	  ={V. Gullapalli and A. G. Barto and R. A. Grupen},
	booktitle ={Robotics and Automation, 1994. Proceedings., 1994 IEEE International Conference on},
	title 	  ={Learning admittance mappings for force-guided assembly},
	year 	  ={1994},
	pages  	  ={2633-2638},
	volume    ={3},
	month     ={May},
	doi  	  = {10.1023/A:1008058131402}
}

@article{Abu-Dakka2014,
	author     = {Abu-Dakka, Fares J. and Nemec, et. al},
	title  	   = {{Solving peg-in-hole tasks by human demonstration and exception strategies}},
	journal    = {Industrial Robot: An International Journal},
	number     = {6},
	pages  	   = {575--584},
	volume     = {41},
	year       = {2014},
	doi 	   = {10.1108/IR-07-2014-0363}
}


@TECHREPORT{Bergman99recursivebayesian,
    author = {Niclas Bergman and C Niclas Bergman},
    title = {Recursive Bayesian estimation: Navigation and tracking applications. Thesis No 579},
    institution = {Link\"oping University, Link\"oping Studies in Science and Technology. Doctoral dissertation},
    year = {1999}
}


@inproceedings{PBVI,
   author 	= "Joelle Pineau and Geoffrey Gordon and Sebastian Thrun",
   title 	= "Point-based value iteration: An anytime algorithm for POMDPs",
   booktitle 	= "International Joint Conference on Artificial Intelligence (IJCAI)",
   pages 	= "1025-1032",
   month 	= "August",
   year 	= "2003"
} 



% RL

@ARTICLE{rl_ac_surv_2012,
	author={I. Grondman and L. Busoniu and G. A. D. Lopes and R. Babuska},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	title={A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients},
	year={2012},
	volume={42},
	number={6},
	pages={1291-1307},
	doi={10.1109/TSMCC.2012.2218595},
	month={Nov}
}

@INPROCEEDINGS{fvi_uav_2010,
	author		={H. Bou-Ammar and H. Voos and W. Ertel},
	booktitle	={International Conference on Control Applications},
	title		={Controller design for quadrotor UAVs using reinforcement learning},
	year		={2010},
	pages 		={2130-2135},
	month 		={Sept},
	doi 		={10.1109/CCA.2010.5611206}
}

@Article{EGW05,
  	author       = "Ernst, Damien and Geurts, Pierre and Wehenkel, Louis",
  	title        = "Tree-Based Batch Mode Reinforcement Learning",
  	journal      = "Journal of Machine Learning Research",
  	volume       = "6",
  	pages        = "503-556",
  	month        = "April",
  	year         = "2005"
 }


@Inbook{Riedmiller2005,
	author 		= "Riedmiller, Martin",
	title		="Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method",
	bookTitle 	="European Conference on Machine Learning",
	publisher 	="Springer Berlin Heidelberg",
	volume 		="16",
	year 		="2005",
	pages 		="317--328",
	doi 		="10.1007/11564096_32"
}

@article{NAC_2008,
	author 		= "Jan Peters and Stefan Schaal",
	title 		= "Natural Actor-Critic ",
	journal 	= "European Symposium on Artificial Neural Networks ",
	volume 		= "71",
	number 		= "7-9",
	pages 		= "1180-1190",
	year 		= "2008",
	doi 		= "10.1016/j.neucom.2007.11.026",
}

@INPROCEEDINGS{rl_gmm_2010,
	author 		={A. Agostini and E. Celaya},
	booktitle	={International Joint Conference on Neural Networks (IJCNN)},
	title 		={Reinforcement Learning with a Gaussian mixture model},
	year 		={2010},
	pages 		={1-8},
	month  		={July},
	doi 		={10.1109/IJCNN.2010.5596306}
}


@ARTICLE{kernel_rl_ormoneit_2002,
	author		={D. Ormoneit and P. Glynn},
	journal		={IEEE Transactions on Automatic Control},
	title 		={Kernel-based reinforcement learning in average-cost problems},
	year		={2002},
	volume 		={47},
	number 		={10},
	pages 		={1624-1636},
	month 		={Oct},
	doi		={10.1109/TAC.2002.803530}
}

@InProceedings{stable_FA_gordon_1995,
 	author 	  = {Gordon, Geoffrey J.},
  	booktitle = {International Conference on Machine Learning (ICML)},
 	title 	  = {Stable Function Approximation in Dynamic Programming},
 	year 	  = {1995},
	pages     = {261-268}
} 



@inproceedings{fqi_nips_peter_2009,
  	title 		= {Fitted Q-iteration by Advantage Weighted Regression},
  	author 		= {Neumann, G. and Peters, J.},
  	booktitle 	= {Advances in neural information processing systems (NIPS)},
	volume 		= {21},
  	pages 		= {1177-1184},
  	month 		= jun,
  	year 		= {2009}
}

@INPROCEEDINGS{Lange_riedmiller_2010,
	author 		={S. Lange and M. Riedmiller},
	booktitle 	={The 2010 International Joint Conference on Neural Networks (IJCNN)},
	title 		={Deep auto-encoder neural networks in reinforcement learning},
	year 		={2010},
	pages	 	={1-8},
	month	 	={July}
}


@article{p_search_surv_2011,
	author 	= {Marc Peter Deisenroth and Gerhard Neumann and Jan Peters},
	year 	= {2011},
	volume  = {2},
	journal = {Foundations and Trends in Robotics},
	title   = {A Survey on Policy Search for Robotics},
	number  = {1-2},
	pages   = {1-142},
	doi 	= {10.1561/2300000021}
}

@INPROCEEDINGS{approx_rl_overview_2011,
	author 		={L. Busoniu and D. Ernst and B. De Schutter and R. Babuska},
	booktitle	={Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
	title		={Approximate reinforcement learning: An overview},
	year 		={2011},
	pages 		={1-8},
	month		={April},
	doi 		={10.1109/ADPRL.2011.5967353}
}


@article{mnih-dqn-2015,
	Author 		= {Mnih, Volodymyr and et. al},
	Title 		= {Human-level control through deep reinforcement learning},
	Journal 	= {Nature},
	Month 		= {feb},
	Pages 		= {529--533},
	Volume 		= {518},
	Year 		= {2015},
	doi  		= {10.1038/nature14236}
}


@article{DRQ_AAAI_2015,
	author 		= {Matthew Hausknecht and Peter Stone},
	title 		= {Deep Recurrent Q-Learning for Partially Observable MDPs},
  	journal   	= {CoRR},
	year 		= {2015}
}

@book{RL_state_art_2012,
  	author	 	= {Wiering, Marco and van Otterio, Martijn},
  	booktitle 	= {Reinforcement Learning State-of-the-Art},
  	publisher 	= {Springer-Verlag Berlin Heidelberg},
  	title 		= {Reinforcement Learning State-of-the-Art},
  	year 		= {2012}
}


@MISC{Kronander2015,
  	author       = {Kronander, K.},
  	title        = {Control and Learning of Compliant Manipulation Skills},
  	year         = {2015}
}



% NEW

@INPROCEEDINGS{toussain_2015,
	author 		={N. A. Vien and M. Toussaint},
	booktitle	={International Conference on Intelligent Robots and Systems (IROS)},
	title		={POMDP manipulation via trajectory optimization},
	year 		={2015},
	pages 		={242-249},
	doi 		={10.1109/IROS.2015.7353381},
	month 		={Sept}
}

@article{Li2016352,
	author 		= "Miao Li and Kaiyu Hang and Danica Kragic and Aude Billard",
	title 		= "Dexterous grasping under shape uncertainty ",
	journal 	= "Robotics and Autonomous Systems",
	volume 		= "75, Part B",	
	pages 		= "352 - 364",
	year 		= "2016",
	doi 		= "10.1016/j.robot.2015.09.008",
}

@article{Lauri2016,
	author 		= "Mikko Lauri and Risto Ritala",
	title 		= "Planning for robotic exploration based on forward simulation ",
	journal 	= "Robotics and Autonomous Systems ",
	year 		= "2016",
	doi 		= "10.1016/j.robot.2016.06.008"
}














