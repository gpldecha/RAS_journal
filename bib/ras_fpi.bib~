@INPROCEEDINGS{peg_personal_icra_2010,
	author		= {Wim Meeussen and Melonee Wise and Stuart Glaser and Sachin Chitta and et. al},
	booktitle	= {International Conference on Robotics and Automation (ICRA)},
	title		= {Autonomous door opening and plugging in with a personal robot},
	year 		= {2010},
	pages 		= {729--736},
	month 		= {May},
	url 	 	= {http://dx.doi.org/10.1109/ROBOT.2010.5509556}
}

@inbook{fast_peg_pbd_icmc_2014,
	title 		= "Fast programming of peg-in-hole actions by human demonstration",
	booktitle 	= "International Conference on Mechatronics and Control (ICMC)",
	author 		= "Yang Yang and Linglong Lin and Song, {Y. T.} and Bojan Nemec and Ales Ude and Buch, {Anders Glent} and Norbert Kruger and Savarimuthu, {Thiusius Rajeeth}",
	year 		= "2014",
	pages 		= "990--995",
	url 		= "http://dx.doi.org/10.1109/ICMC.2014.7231702",
}

@inproceedings{learn_admittance_icra_1994,
  	author    = {Gullapalli, Vijaykumar and Barto, Andrew and Grupen, Roderic},
  	title     = {Learning Admittance Mappings for Force-Guided Assembly},
  	booktitle = {International Conference on Robotics and Automation (ICRA)},
  	pages     = {2633--2638},
  	year      = {1994},
  	month     = {may},
  	url       = {http://dx.doi.org/10.1109/ROBOT.1994.351117}
}


@INPROCEEDINGS{online_gpr_icra_2014,
	author		={Hongtai Cheng and Heping Chen},
	booktitle	={International Conference on Robotics and Automation (ICRA)},
	title		={Online parameter optimization in robotic force controlled assembly processes},
	year		={2014},
	pages		={3465-3470},
	month		={may},
	url		={http://dx.doi.org/10.1109/ICRA.2014.6907358},
}


@INPROCEEDINGS{feed_icra_2010,
	author		= {Mayton, Brian and LeGrand, Louis and Smith, Joshua R.},
	booktitle	= {International Conference on Robotics and Automoation (ICRA)},
	title		= {Robot, feed thyself: Plugging in to unmodified electrical outlets by sensing emitted AC electric fields},
	year		= {2010},
	pages		= {715-722},
	month		= {May},
	url		= {http://dx.doi.org/10.1109/ROBOT.2010.5509643}
}

@INPROCEEDINGS{pomdp_peg_icra_2014,
	author 		={Hongtai Cheng and Heping Chen and Lina Hao and Wei Li},
	booktitle	={International Conference on Robotics and Automation (ICRA)},
	title		={Robot learning based on Partial Observable Markov Decision Process in unstructured environment},
	year		={2014},
	pages		={4399--4404},
	month		={May},
	url		={http://dx.doi.org/10.1109/ICRA.2014.6907500}
}

@INPROCEEDINGS{search_strategies_icra_2001,
	author		={Siddharth, Chhatpar and Branicky, Michael},
	booktitle	={International Conference on Intelligent Robots and Systems (ICRA)},
	title		={Search strategies for peg-in-hole assemblies with position uncertainty},
	year		={2001},
	volume		={3},
	pages		={1465--1470},
	url		={http://dx.doi.org/10.1109/IROS.2001.977187},
}

@article{sol_pdg_pbd_2014,
	author 		= "Fares Abu-Dakka and Bojan Nemec and Aljaz Kramberger and Anders Glent Buch and Norbert Kr{\"u}ger and Ales Ude",
	journal 	= "Industrial Robot",
	number 		= "6",
	pages 		= "575--584",
	title 		= "Solving peg-in-hole tasks by human demonstration and exception strategies",
	volume 		= "41",
	year 		= "2014",
	url 		= "http://dx.doi.org/10.1108/IR-07-2014-0363"
}

@INPROCEEDINGS{learn_force_c_icirs_2011,
	author		= {Mrinal Kalakrishnan and Ludovic Righetti and Peter Pastor and Stefan Schaal},
	booktitle	= {International Conference on Intelligent Robots and Systems (ICRA)},
	title		= {Learning force control policies for compliant manipulation},
	year		= {2011},
	pages		= {4639--4644},
	month		= {Sept},
	url		= {http://dx.doi.org/10.1109/IROS.2011.6095096},
}

@INPROCEEDINGS{Schaal04learningmovement,
    	author 		= {Stefan Schaal and Jan Peters and Jun Nakanishi and Auke Ijspeert},
    	title 		= {Learning movement primitives},
    	booktitle 	= {11th International Symposium on Robotics Research (ISRR)},
    	year 		= {2004},    	
	url 		= {http://dx.doi.org/10.1007/11008941_60}
}

@INPROCEEDINGS{trans_workpiece_icra_2013,
	author 		= {Bojan Nemec and Fares Abu-Dakka and Barry Ridge and et. al},
	booktitle	= {International Conference on Advanced Robotics (ICAR)},
	title		= {Transfer of assembly operations to new workpiece poses by adaptation to the desired force profile},
	year		= {2013},
	pages		= {1--7},
	month		= {Nov},
	url		= {http://dx.doi.org/10.1109/ICAR.2013.6766568}
}	

@INPROCEEDINGS{compliant_manip_icra_2008,
	author		= {Seung-kook Yun},
	booktitle	= {International Conference on Robotics and Automation (ICRA)},
	title		= {Compliant manipulation for peg-in-hole: Is passive compliance a key to learn contact motion?},
	year		= {2008},
	pages		= {1647-1652},
	month		= {May},
	url		= {http://dx.doi.org/10.1109/ROBOT.2008.4543437}
}

@article{rl_gradient_survey_2013,
	author 		= {Marc Peter Deisenroth and Gerhard Neumann and Jan Peters},
	title	 	= {A Survey on Policy Search for Robotics},
	year 		= {2013},
	volume 		= {2},
	journal 	= {Foundations and Trends in Robotics},
	number 		= {1-2},
	pages 		= {1--142},
	url 		= {http://dx.doi.org/10.1561/2300000021}
}

@Article{Kober2011,
	author		="Kober, Jens and Peters, Jan",
	title		="Policy search for motor primitives in robotics",
	journal		="Machine Learning",
	year		="2011",
	volume		="84",
	number		="1",
	pages		="171--203",
	url		="http://dx.doi.org/10.1007/s10994-010-5223-6"
}

@article{Kormushev_MDPI_2013,
  	author 		= {Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin},
  	title 		= {Reinforcement Learning in Robotics: Applications and Real-World Challenges},
  	journal 	= {Robotics},
  	volume 		= {2},
  	year 		= {2013},
  	number 		= {3},
  	pages 		= {122--148},
  	url 		= {http://dx.doi.org/10.3390/robotics2030122}
}

@INPROCEEDINGS{dmp_grasp_iros_2011,
	author		={Freek Stulp and Evangelos Theodorou and Mrinal Kalakrishnan and Peter Pastor and Ludovic Righetti and Stefan Schaal},
	booktitle	={International Conference on Intelligent Robots and Systems (IROS)},
	title		={Learning motion primitive goals for robust manipulation},
	year		={2011},
	pages		={325--331},
	month		={Sept},
	url		={http://dx.doi.org/10.1109/IROS.2011.6094877}
}


@Article{Chambrier2014,
	author 		="Chambrier, Guillaume de and Billard, Aude",
	title 		="Learning search policies from humans in a partially observable context",
	journal 	="Journal of Robotics and Biomimetics",
	year 		="2014",
	volume 		="1",
	number 		="1",
	pages 		="1--16",
	doi 		="10.1186/s40638-014-0008-1"
}

@article{peter_nac_2008,
  	title 		= {Natural Actor-Critic},
  	author 		= {Peters, Jan and Schaal, Stefan},
  	journal 	= {Neurocomputing},
  	volume 		= {71},
  	number 		= {7-9},
  	pages 		= {1180--1190},
  	year 		= {2008},
  	month 		= {mar},
	url 		= {http://dx.doi.org/10.1016/j.neucom.2007.11.026}

}

@ARTICLE{gesture_calinon_2010,
	author		={Sylvain Calinon and Florent D'halluin and Eric Sauser and Darwin Caldwell and Aude Billard},
	journal		={Robotics Automation Magazine},
	title		={Learning and Reproduction of Gestures by Imitation},
	year		={2010},
	volume		={17},
	number 		={2},
	pages	 	={44--54},
	month		={jun},
	url		={http://dx.doi.org/10.1109/MRA.2010.936947}, 
}

@phdthesis{gmr_2004,
  	author       	= {Sung, Hsi Guang}, 
  	title        	= {Gaussian Mixture Regression and Classification},
  	school       	= {Rice University},
  	year         	= 2004
}

@article{DeisenrothNP2013,
  	title 		= {A Survey on Policy Search for Robotics},
  	author 		= {Marc Deisenroth, Gerhard Neumann and Jan Peters},
  	journal  	= {Foundations and Trends in Robotics},
  	volume 		= {2},
  	number 		= {1-2},
  	pages 		= {1--142},
  	year 		= {2013},
	url 		= {http://dx.doi.org/10.1561/2300000021}
}


@Book{Szepesvari:2010,
  	author 		= "Szepesv{\'a}ri, Csaba",
  	title 		= "Algorithms for Reinforcement Learning",
  	publisher 	= "Morgan {\&} Claypool",
  	year 		= "2010",
  	url 		= "http://www.sztaki.hu/~szcsaba/papers/RLAlgsInMDPs-lecture.pdf",
  }


@INPROCEEDINGS{Boyan95generalizationin,
    	author 		= {Justin Boyan and Andrew Moore},
    	title 		= {Generalization in Reinforcement Learning: Safely Approximating the Value Function},
    	booktitle 	= {Advances in Neural Information Processing Systems (NIPS)},
    	volume 		= {7},
    	year 		= {1995},
    	pages 		= {369--376}    
}

@ARTICLE{Atkeson97locallyweighted,
    	author 		= {Christopher Atkeson and Andrew Moore and Stefan Schaal},
    	title 		= {Locally weighted learning},
    	journal 	= {Artificial Inteligence},
    	year 		= {1997},
    	pages 		= {11--73},
	url 		= {http://dx.doi.org/10.1023/A:1006559212014}
}

@incollection{NIPS2008_3501,
	title  		= {Fitted Q-iteration by Advantage Weighted Regression},
	author  	= {Neumann, Gerhard and Jan R. Peters},
	booktitle  	= {Advances in Neural Information Processing Systems (NIPS) },
	volume  	= {21},
	publisher 	= {Curran Associates, Inc.},
	editor  	= {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
	pages  		= {1177--1184},
	year  		= {2009}
}

@BOOK{sutton1998reinforcement,
  	author 		= {Sutton, Richard and Barto, Andrew},
  	title 		= {Reinforcement Learning: An Introduction},
  	publisher 	= {MIT Press},
  	year 		= {1998},
  	address 	= {Cambridge, MA}
}

@Book{Bishop_2006,
  author =       "Bishop, Christopher",
  title =        "Pattern Recognition and Machine Learning",
  publisher =    "Springer",
  year =         "2006"
}


@article{EBurdet1999,
	author 		= {Burdet, Etienne and Nuttin, Marnix},
	journal 	= {Journal of Intelligent and Robotic Systems},
	number 		= {1},
	pages 		= {43--68},
	title 		= {Learning Complex Tasks Using a Stepwise Approach},
	volume 		= {24},
	url 		= {http://dx.doi.org/10.1023/A:1008058131402}
}


@INPROCEEDINGS{Gullapalli_1994,
	author		={Vijaykumar Gullapalli and Andrew Barto and Roderic Grupen},
	booktitle	={International Conference on Robotics and Automation (ICRA)},
	title 		={Learning admittance mappings for force-guided assembly},
	year 		={1994},
	pages		={2633-2638},
	volume 		={3},
	month 		={May},
	url 		={http://dx.doi.org/10.1109/ROBOT.1994.351117}
}

@article{Abu-Dakka2014,
	author 		= {Abu-Dakka, Fares and Nemec, Bojan and Kramberger, Alja{\v{z}} and Buch, Anders Glent and Kr{\"{u}}ger, Norbert and Ude, Ales},
	journal 	= {Industrial Robot: An International Journal},
	number 		= {6},
	pages 		= {575--584},
	title 		= {Solving peg-in-hole tasks by human demonstration and exception strategies},
	volume 		= {41},
	year 		= {2014},
	url 		= {http://dx.doi.org/10.1108/IR-07-2014-0363}
}


@TECHREPORT{Bergman99recursivebayesian,
    	author 		= {Niclas Bergman and Niclas Bergman},
    	title 		= {Recursive Bayesian estimation: Navigation and tracking applications. Thesis No 579},
    	institution 	= {Link\"oping University, Link\"oping Studies in Science and Technology. Doctoral dissertation},
    	year 		= {1999}
}


@INPROCEEDINGS{PBVI_2003,
  	author 		= {Pineau, Joelle and Gordon, Geoff and Thrun, Sebastian},
  	title 		= {Point-based value iteration: an anytime algorithm for POMDPs},
  	booktitle 	= {International Joint Conference on Artificial Intelligence (IJCAI)},
  	year 		= {2003},
	month		= {Aug},
  	pages 		= {1025--1030},
 	url 		= {http://dl.acm.org/citation.cfm?id=1630659.1630806}
}

@article{cPBVI_2006,
 	author 		= {Porta, Josep and Vlassis, Nikos and Spaan, Matthijs and Poupart, Pascal},
 	title 		= {Point-Based Value Iteration for Continuous POMDPs},
 	journal 	= {J. Mach. Learn. Res.},
 	volume 		= {7},
 	month 		= {Dec},
 	year 		= {2006},
 	pages 		= {2329--2367},
 	url 		= {http://dl.acm.org/citation.cfm?id=1248547.1248630},
 } 

@INPROCEEDINGS{Baxter_GPOMDP_2000,
    	author 		= {Jonathan Baxter and Peter Bartlett},
    	title 		= {Reinforcement Learning in POMDP's via Direct Gradient Ascent},
    	booktitle 	= {International Conference on Machine Learning},
    	year 		= {2000},
	volume 		= {17},
    	pages 		= {41--48}
}


@InProceedings{Veiga14aaai,
  	author 		= {Tiago Veiga and Matthijs Spaan and Pedro Lima},
  	title 		= {Point-based {POMDP} Solving with Factored Value Function Approximation},
  	booktitle 	= {Conference on Artificial Intelligence (AAAI)},
  	volume    	= {28},
  	year 		= {2014},
  	pages 		= {2512--2518}
}

% RL

@ARTICLE{rl_ac_surv_2012,
	author 		= {Ivo Grondman and Lucian Busoniu and Gabriel Lopes and Robert Babuska},
	journal 	= {Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	title 		= {A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients},
	year 		= {2012},
	volume 		= {42},
	number 		= {6},
	pages 		= {1291--1307},
	month 		= {Nov},
	url 		= {http://dx.doi.org/10.1109/TSMCC.2012.2218595}
}

@INPROCEEDINGS{fvi_uav_2010,
	author 		= {Haitham Bou-Ammar and Holger Voos and Wolfgang Ertel},
	booktitle 	= {International Conference on Control Applications},
	title 		= {Controller design for quadrotor UAVs using reinforcement learning},
	year 		= {2010},
	pages 		= {2130--2135},
	month 		= {Sept},
	url 		= {http://dx.doi.org/10.1109/CCA.2010.5611206},
}

@Article{EGW05,
  	author       = "Ernst, Damien and Geurts, Pierre and Wehenkel, Louis",
  	title        = "Tree-Based Batch Mode Reinforcement Learning",
  	journal      = "Journal of Machine Learning Research",
  	volume       = "6",
  	pages        = "503-556",
  	month        = "April",
  	year         = "2005",
 }

@Inbook{Riedmiller2005,
	author 		= "Riedmiller, Martin",
	title		="Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method",
	bookTitle 	="European Conference on Machine Learning",
	volume 		="16",
	year 		="2005",
	pages 		="317--328",
	url		="http://dx.doi.org/10.1007/11564096_32"
}

@article{NAC_2008,
	title 		= "Natural Actor-Critic ",
	journal 	= "European Symposium on Artificial Neural Networks ",
	volume 		= "71",
	number 		= "7-9",
	pages 		= "1180--1190",
	year 		= "2008",
	author 		= "Jan Peters and Stefan Schaal",
	url 		= "http://dx.doi.org/10.1016/j.neucom.2007.11.026"
}

@INPROCEEDINGS{rl_gmm_2010,
	author 		= {Alejandro Agostini and Enric Celaya},
	booktitle	= {International Joint Conference on Neural Networks (IJCNN)},
	title		= {Reinforcement Learning with a Gaussian mixture model},
	year		= {2010},
	pages		= {1--8},
	month 		= {July},
	url 		= {http://dx.doi.org/10.1109/IJCNN.2010.5596306}
}


@ARTICLE{kernel_rl_ormoneit_2002,
	author		= {Dirk Ormoneit and Peter Glynn},
	journal		= {Transactions on Automatic Control},
	title		= {Kernel-based reinforcement learning in average-cost problems},
	year		= {2002},
	volume		= {47},
	number		= {10},
	pages		= {1624--1636},
	month		= {Oct},
	url		= {http://dx.doi.org/10.1109/TAC.2002.803530}
}

@InProceedings{stable_FA_gordon_1995,
 	author 	  = {Gordon, Geoffrey},
  	booktitle = {International Conference on Machine Learning (ICML)},
 	title 	  = {Stable Function Approximation in Dynamic Programming},
 	year 	  = {1995}
  	url 	  = {"http://www.cs.cmu.edu/~ggordon/ml95-stable-dp.ps.gz"}
} 


@incollection{NIPS1995_1133,
	author 		= {Gordon, Geoffrey},
	booktitle 	= {Advances in Neural Information Processing Systems (NIPS)},
	volume 		= {8},
	pages 		= {1052--1058},
	title 		= {{Stable Fitted Reinforcement Learning}},
	url 		= {http://papers.nips.cc/paper/1133-stable-fitted-reinforcement-learning.pdf},
	year 		= {1996}
}


@inproceedings{fqi_nips_peter_2009,
  	title 		= {Fitted Q-iteration by Advantage Weighted Regression},
  	author 		= {Neumann, Gerhard and Peters, Jan},
  	booktitle 	= {Advances in Neural Information Processing Systems (NIPS)},
 	volume 		= {21},
  	pages 		= {1177-1184},
  	month 		= {Jun},
  	year 		= {2009}
}

@INPROCEEDINGS{Lange_riedmiller_2010,
	author 		={Sascha Lange and Martin Riedmiller},
	booktitle 	={International Joint Conference on Neural Networks (IJCNN)},
	title 		={Deep auto-encoder neural networks in reinforcement learning},
	year 		={2010},
	pages	 	={1-8},
	month	 	={July}
}


@article{p_search_surv_2011,
	author 	= {Marc Peter Deisenroth and Gerhard Neumann and Jan Peters},
	year 	= {2013},
	volume  = {2},
	journal = {Foundations and Trends in Robotics},
	title   = {A Survey on Policy Search for Robotics},
	number  = {1-2},
	pages   = {1--142},
	url 	= {http://dx.doi.org/10.1561/2300000021}
}


@INPROCEEDINGS{approx_rl_overview_2011,
	author		= {Lucian Busoniu and Damien Ernst and Bart {de Schutter} and Robert. Babuska},
	booktitle	= {Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
	title		= {Approximate reinforcement learning: An overview},
	year		= {2011},
	pages		= {1-8},
	month		= {April},
	url		= {http://dx.doi.org/10.1109/ADPRL.2011.5967353}
}


@article{mnih-dqn-2015,
	Author 		= {Mnih, Volodymyr},
	Journal 	= {Nature},
	Month 		= {02},
	Number 		= {7540},
	Pages 		= {529--533},
	Title 		= {Human-level control through deep reinforcement learning},
	Volume 		= {518},
	Year 		= {2015},
	url 		= {http://dx.doi.org/10.1038/nature14236}
}

@article{DRQ_AAAI_2015,
	author 		= {Matthew Hausknecht and Peter Stone},
	title 		= {Deep Recurrent Q-Learning for Partially Observable MDPs},
	journal 	= {Association for the Advancement of Artificial Intelligence (AAAI)},
	year 		= {2015},
	url 		= {https://www.aaai.org/ocs/index.php/FSS/FSS15/paper/view/11673}
}

@book{RL_state_art_2012,
  	author	 	= {Wiering, Marco and van Otterio, Martijn},
  	booktitle 	= {Reinforcement Learning State-of-the-Art},
  	title 		= {Reinforcement Learning State-of-the-Art},
  	year 		= {2012}
}


@MISC{Kronander2015,
  	author       = {Kronander, K.},
  	title        = {Control and Learning of Compliant Manipulation Skills},
  	year         = {2015}
}



% NEW

@INPROCEEDINGS{toussain_2015,
	author		= {Ngo Vien and Marc Toussaint},
	booktitle	= {International Conference on Intelligent Robots and Systems (IROS)},
	title		= {POMDP manipulation via trajectory optimization},
	year		= {2015},
	pages		= {242--249},
	month		= {Sept},
	url		= {http://dx.doi.org/10.1109/IROS.2015.7353381}
}

@article{Li2016352,
	author 		= "Miao Li and Kaiyu Hang and Danica Kragic and Aude Billard",
	title 		= "Dexterous grasping under shape uncertainty ",
	journal 	= "Robotics and Autonomous Systems",
	volume 		= "75, Part B",	
	pages 		= "352 - 364",
	year 		= "2016",
	doi 		= "10.1016/j.robot.2015.09.008",
}

@article{Lauri2016,
	author 		= "Mikko Lauri and Risto Ritala",
	title 		= "Planning for robotic exploration based on forward simulation ",
	journal 	= "Robotics and Autonomous Systems ",
	year 		= "2016",
	doi 		= "10.1016/j.robot.2016.06.008"
}



@article{Ross08onlineplanning,
 	author 	= {Ross, St{\'e}phane and Pineau, Joelle and Paquet, S{\'e}bastien and Chaib-draa, Brahim},
 	title 	= {Online Planning Algorithms for POMDPs},
 	journal = {Journal Artifcial Intelligence Research},
 	volume 	= {32},
 	number 	= {1},
 	month 	= {Jul},
 	year 	= {2008},
 	pages 	= {663--704},
 	url 	= {http://dl.acm.org/citation.cfm?id=1622673.1622690},
} 



@article{Milos_POMDP_2000,
 	author = {Hauskrecht, Milos},
 	title = {Value-function Approximations for Partially Observable Markov Decision Processes},
 	journal = {Journal of Artificial Intelligence Research},
  	volume = {13},
 	number = {1},
 	month = {Aug},
 	year = {2000},
 	pages = {33--94},
 	url = {http://dl.acm.org/citation.cfm?id=1622262.1622264}
 } 

@article{Sondik_1973,
	author 		= {Richard Smallwood and Edward Sondik},
 	title 		= {The Optimal Control of Partially Observable Markov Processes over a Finite Horizon},
 	journal 	= {Journal of Operational Research},
 	volume 		= {21},
 	number 		= {5},
 	month 		= {Oct},
 	year 		= {1973},
 	pages 		= {1071--1088},
 	url 		= {http://dx.doi.org/10.1287/opre.21.5.1071}
}


@BOOK{Thrun_Burgard_Fox_2005,
  	author 		= {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  	title 		= {Probabilistic Robotics},
  	year 		= {2005}
}



@INPROCEEDINGS{SARSOP,
  	author 		= {Hanna Kurniawati and David Hsu and Wee Sun Lee},
  	title 		= {SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces},
  	booktitle 	= {Robotics Science and Systems (RSS)},
  	year 		= {2008}
}

@INPROCEEDINGS{POMDP_approach_2010,
	AUTHOR = "Yanzhu Du and David Hsu and Hanna Kurniawati and Wee Lee and Sylvie Ong and Shao Png",
	TITLE = "A POMDP Approach to Robot Motion Planning under Uncertainty",
	BOOKTITLE = "International Conference on Automated Planning and Scheduling, Workshop on Solving Real-World POMDP Problems",
	YEAR = "2010"
}

@TECHREPORT{Bilmes97agentle,
    author = {Jeff Bilmes},
    title = {A gentle tutorial on the EM algorithm and its application to parameter estimation for gaussian mixture and hidden markov models},
    year = {1997},
    doi={10.1.1.28.613}
}



@incollection{Thrun_1999,
	author 		= {Thrun, Sebastian},
	booktitle 	= {Advances in Neural Information Processing Systems (NIPS)},
	volume 		= {12},
	pages 		= {1064--1070},
	title 		= {{Monte Carlo POMDPs}},
	url 		= {http://papers.nips.cc/paper/1772-monte-carlo-pomdps.pdf},
	year 		= {2000}
}


@INPROCEEDINGS{Jodogne2006,
	author 		= {Jodogne, S{\'{e}}bastien and Briquet, Cyril and Piater, Justus H},
	booktitle 	= { European Conference on Machine Learning},
	doi 		= {10.1007/11871842_23},
	volume		= {17},
	pages 		= {210--221},
	title 		= {{Approximate Policy Iteration for Closed-Loop Learning of Visual Tasks}},
	url 		= {http://dx.doi.org/10.1007/11871842{\_}23},
	year 		= {2006}
}


@inbook{Melo2008,
	author 		= {Melo, Francisco S and Lopes, Manuel},
	booktitle 	= {Machine Learning and Knowledge Discovery in Databases},
	doi 		= {10.1007/978-3-540-87481-2_5},
	editor 		= {Daelemans, Walter and Goethals, Bart and Morik, Katharina},
	isbn 		= {978-3-540-87481-2},
	pages 		= {66--81},
	title 		= {{Fitted Natural Actor-Critic: A New Algorithm for Continuous State-Action MDPs}},
	url 		= {http://dx.doi.org/10.1007/978-3-540-87481-2{\_}5},
	year 		= {2008}
}


@article{PPOMDP_2006,
	author = {Brooks, Alex and Makarenko, Alexei and Williams, Stefan and Durrant-Whyte, Hugh},
	doi = {http://dx.doi.org/10.1016/j.robot.2006.05.007},
	issn = {0921-8890},
	journal = {Robotics and Autonomous Systems},
	number = {11},
	pages = {887--897},
	title = {{Parametric {\{}POMDPs{\}} for planning in continuous state spaces}},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889006000960},
	volume = {54},
	year = {2006}
}

@article{LSPI_2003,
 	author 		= {Lagoudakis, Michail G. and Parr, Ronald},
 	title 		= {Least-squares Policy Iteration},
 	journal 	= {Journal of Machine Learning Research},
 	volume 		= {4},
 	month 		= {dec},
 	year 		= {2003},
 	pages 		= {1107--1149},
 	url 		= {http://dl.acm.org/citation.cfm?id=945365.964290}
} 

@article{Calinon2013369,
	author 		= {Calinon, Sylvain and Kormushev, Petar and Caldwell, Darwin G},
	doi 		= {http://dx.doi.org/10.1016/j.robot.2012.09.012},
	issn 		= {0921-8890},
	journal 	= {Robotics and Autonomous Systems},
	keywords 	= {Dynamical systems,Expectation-maximization,Gaussian mixture model,Learning by imitation,Reinforcement learning,Skills transfer},
	number 		= {4},
	pages 		= {369--379},
	title 		= {{Compliant skills acquisition and multi-optima policy search with EM-based reinforcement learning}},
	url 		= {http://www.sciencedirect.com/science/article/pii/S0921889012001662},
	volume 		= {61},
	year 		= {2013}
}

@inproceedings{Kormushev2010Humanoids,
  	author		= "Kormushev, Petar and Calinon, S. and Saegusa, R. and Metta, G.",
  	title 		= "Learning the skill of archery by a humanoid robot {iCub}",
  	booktitle 	= "International Conference on Humanoid Robots ({H}umanoids)",
  	month 		= "December",
  	year 		= "2010",
  	address 	= "Nashville, USA",
  	pages		= "417-423",
  	url 		= "http://kormushev.com/papers/Kormushev_Humanoids-2010.pdf"
}


@INPROCEEDINGS{Baird95,
    author 		= {Leemon Baird},
    title 		= {Residual Algorithms: Reinforcement Learning with Function Approximation},
    booktitle 		= {International Conference on Machine Learning (ICML)},
    year 		= {1995},
    pages 		= {30--37}
}



@INPROCEEDINGS{Sutton00policygradient,
    author 		= {Richard S. Sutton and David Mcallester and Satinder Singh and Yishay Mansour},
    title 		= {Policy gradient methods for reinforcement learning with function approximation},
    booktitle 		= {Neural Information Processing Systems (NIPS)},
    doi 	        = {10.1.1.79.5189},
    volume 		= {12},
    year 		= {2000},
    pages 		= {1057--1063}
}

@Article{Bertsekas2011,
	author		="Bertsekas, Dimitri",
	title		="Approximate policy iteration: a survey and some new methods",
	journal		="Journal of Control Theory and Applications",
	year		="2011",
	volume		="9",
	number		="3",
	pages		="310--335",
	issn		="1993-0623",
	url		="http://dx.doi.org/10.1007/s11768-011-1005-3"
}

@book{Neuro_1996,
 	author 		= {Bertsekas, Dimitri and Tsitsiklis, John},
 	title 		= {Neuro-Dynamic Programming},
 	year 		= {1996},
 	edition 	= {1st}
} 

@ARTICLE{Khansari_Billard_TRO11,
  	author 	= {Khansari-Zadeh,  Mohammed and Billard, Aude},
  	title 	= {Learning {S}table {N}on-{L}inear {D}ynamical {S}ystems with {G}aussian {M}ixture {M}odels},
  	journal = {{T}ransaction on {R}obotics (TRO)},
  	year 	= {2011}
}


@article{stulp12reinforcement,
  	title 	= {{Reinforcement Learning with Sequences of Motion Primitives for Robust Manipulation}},
  	author 	= {Stulp, F. and Theodorou, E. and Schaal, S.},
  	journal = {Transactions on Robotics (TRO)},
  	year 	= {2012}
}
@article{belief_compression_2005,
    	author 	= {Roy, Nicholas},
     	journal = {Journal of Artificial Intelligence Research},
    	title 	= {{Finding Approximate POMDP solutions Through Belief Compression}},
    	url    	= {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.6180},
    	volume 	= {23},
    	year = 	{2005}
}











